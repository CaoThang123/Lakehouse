{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e175cee-725f-4564-ab3a-389f236b5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "\n",
    "AWS_ACCESS_KEY = \"minioadmin\"\n",
    "AWS_SECRET_KEY = \"minioadmin\"\n",
    "AWS_S3_ENDPOINT = \"http://minio_server:9000\"\n",
    "WAREHOUSE = \"s3a://gold/\" \n",
    "NESSIE_URI = \"http://nessie:19120/api/v1\"\n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "    .setAppName(\"Lakehouse-Iceberg-TrainModel\")  \n",
    "    .set('spark.jars.packages',\n",
    "         'org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.1,'\n",
    "         'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.3_2.12:0.67.0,'\n",
    "         'org.apache.hadoop:hadoop-aws:3.3.4,'\n",
    "         'com.amazonaws:aws-java-sdk-bundle:1.12.300')\n",
    "    .set(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .set(\"spark.sql.catalog.nessie.uri\", NESSIE_URI)\n",
    "    .set(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .set(\"spark.sql.catalog.nessie.authentication.type\", \"NONE\")\n",
    "    .set(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .set(\"spark.sql.catalog.nessie.warehouse\", WAREHOUSE)\n",
    "    .set(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "    .set(\"spark.sql.catalog.nessie.s3.endpoint\", AWS_S3_ENDPOINT)\n",
    "    .set(\"spark.sql.catalog.nessie.s3.access-key\", AWS_ACCESS_KEY)\n",
    "    .set(\"spark.sql.catalog.nessie.s3.secret-key\", AWS_SECRET_KEY)\n",
    "    .set(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "    .set(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf) \n",
    "    .config(\"spark.driver.memory\", \"4g\") \n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ef4461-7031-4e5b-ac78-36c97526da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact = spark.table(\"nessie.fact_order\")\n",
    "df_customer = spark.table(\"nessie.dim_customer\")\n",
    "df_product = spark.table(\"nessie.dim_product\")\n",
    "df_time = spark.table(\"nessie.dim_time\")\n",
    "df_location = spark.table(\"nessie.dim_location\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b04c6d-f2f6-47c4-9379-80f4bcf71adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT  \n",
    "    f.time_id,\n",
    "    f.customer_id,\n",
    "    f.product_id,\n",
    "    f.location_id,\n",
    "    f.purchase_price_per_unit,\n",
    "    f.quantity,\n",
    "    f.total_price,\n",
    "\n",
    "    -- Dim_time\n",
    "    t.order_date,\n",
    "    t.year,\n",
    "    t.month,\n",
    "    t.day,\n",
    "    t.quarter,\n",
    "    t.weekday_name,\n",
    "\n",
    "    -- Dim_customer\n",
    "    c.age_group,\n",
    "    c.gender,\n",
    "    c.education,\n",
    "    c.income,\n",
    "    c.race,\n",
    "    c.state,\n",
    "\n",
    "    -- Dim_product\n",
    "    p.product_title,\n",
    "    p.product_category,\n",
    "\n",
    "    -- Dim_location\n",
    "    l.state_code,\n",
    "    l.state_name,\n",
    "    l.region\n",
    "\n",
    "FROM nessie.fact_order AS f\n",
    "LEFT JOIN nessie.dim_time AS t ON f.time_id = t.time_id\n",
    "LEFT JOIN nessie.dim_customer AS c ON f.customer_id = c.customer_id\n",
    "LEFT JOIN nessie.dim_product AS p ON f.product_id = p.product_id\n",
    "LEFT JOIN nessie.dim_location AS l ON f.location_id = l.location_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a164bcbf-8f43-4bef-92c1-26b5229ebaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>purchase_price_per_unit</th>\n",
       "      <th>quantity</th>\n",
       "      <th>total_price</th>\n",
       "      <th>order_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "      <th>race</th>\n",
       "      <th>state</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439</td>\n",
       "      <td>R_1jZkLNE1JdtyVpH</td>\n",
       "      <td>000217653X</td>\n",
       "      <td>44</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.99</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>Less than $25,000</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Florida</td>\n",
       "      <td>THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>FL</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439</td>\n",
       "      <td>R_1jZkLNE1JdtyVpH</td>\n",
       "      <td>000217653X</td>\n",
       "      <td>39</td>\n",
       "      <td>13.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.55</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>Less than $25,000</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Florida</td>\n",
       "      <td>THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444</td>\n",
       "      <td>R_3qIPMah81MezsJn</td>\n",
       "      <td>0007137508</td>\n",
       "      <td>33</td>\n",
       "      <td>19.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.95</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>$50,000 - $74,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Wellington: The Iron Duke</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>TN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>428</td>\n",
       "      <td>R_vD2O13NgdnWBXMt</td>\n",
       "      <td>0007302622</td>\n",
       "      <td>4</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$50,000 - $74,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Duck in the Truck</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573</td>\n",
       "      <td>R_1QsZS0nI2sw5gl5</td>\n",
       "      <td>000745287X</td>\n",
       "      <td>41</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.96</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Sharpe's Regiment: Richard Sharpe and the Inva...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>GA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1815</td>\n",
       "      <td>R_2aldwxmUZox7Yfd</td>\n",
       "      <td>0007483791</td>\n",
       "      <td>16</td>\n",
       "      <td>10.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>California</td>\n",
       "      <td>Deep Time</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>R_3GD1CL4OyjglmbZ</td>\n",
       "      <td>0007510837</td>\n",
       "      <td>36</td>\n",
       "      <td>24.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.04</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Collins German Dictionary Complete and Unabrid...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>PA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>328</td>\n",
       "      <td>R_3Pc1ZZfNy58AvgE</td>\n",
       "      <td>0007544790</td>\n",
       "      <td>16</td>\n",
       "      <td>18.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>$100,000 - $149,999</td>\n",
       "      <td>Other</td>\n",
       "      <td>California</td>\n",
       "      <td>My Virgin Kitchen: Delicious recipes you can m...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>354</td>\n",
       "      <td>R_27Nf8ImFlWu3J9O</td>\n",
       "      <td>000756032X</td>\n",
       "      <td>4</td>\n",
       "      <td>9.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2018-06-20</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>Less than $25,000</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>California</td>\n",
       "      <td>Born into the Children of God: My life in a re...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1201</td>\n",
       "      <td>R_3Pp1HTLxoglta9u</td>\n",
       "      <td>0008100713</td>\n",
       "      <td>32</td>\n",
       "      <td>23.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$75,000 - $99,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Well Gardened Mind</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>OH</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id        customer_id  product_id  location_id  \\\n",
       "0      439  R_1jZkLNE1JdtyVpH  000217653X           44   \n",
       "1      439  R_1jZkLNE1JdtyVpH  000217653X           39   \n",
       "2      444  R_3qIPMah81MezsJn  0007137508           33   \n",
       "3      428  R_vD2O13NgdnWBXMt  0007302622            4   \n",
       "4     1573  R_1QsZS0nI2sw5gl5  000745287X           41   \n",
       "5     1815  R_2aldwxmUZox7Yfd  0007483791           16   \n",
       "6       23  R_3GD1CL4OyjglmbZ  0007510837           36   \n",
       "7      328  R_3Pc1ZZfNy58AvgE  0007544790           16   \n",
       "8      354  R_27Nf8ImFlWu3J9O  000756032X            4   \n",
       "9     1201  R_3Pp1HTLxoglta9u  0008100713           32   \n",
       "\n",
       "   purchase_price_per_unit  quantity  total_price  order_date  year  month  \\\n",
       "0                    29.99       1.0        29.99  2020-09-16  2020      9   \n",
       "1                    13.55       1.0        13.55  2020-09-16  2020      9   \n",
       "2                    19.95       1.0        19.95  2022-12-05  2022     12   \n",
       "3                    13.25       1.0        13.25  2019-08-10  2019      8   \n",
       "4                    14.96       1.0        14.96  2022-06-27  2022      6   \n",
       "5                    10.84       1.0        10.84  2018-03-21  2018      3   \n",
       "6                    24.04       1.0        24.04  2020-01-21  2020      1   \n",
       "7                    18.72       1.0        18.72  2019-07-23  2019      7   \n",
       "8                     9.99       1.0         9.99  2018-06-20  2018      6   \n",
       "9                    23.08       1.0        23.08  2022-06-08  2022      6   \n",
       "\n",
       "   ...  gender                                          education  \\\n",
       "0  ...  Female                         High school diploma or GED   \n",
       "1  ...  Female                         High school diploma or GED   \n",
       "2  ...    Male                                  Bachelor's degree   \n",
       "3  ...  Female  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "4  ...    Male  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "5  ...    Male  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "6  ...  Female                         High school diploma or GED   \n",
       "7  ...    Male                                  Bachelor's degree   \n",
       "8  ...    Male                         High school diploma or GED   \n",
       "9  ...    Male  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "\n",
       "                income                race         state  \\\n",
       "0    Less than $25,000  White or Caucasian       Florida   \n",
       "1    Less than $25,000  White or Caucasian       Florida   \n",
       "2    $50,000 - $74,999  White or Caucasian     Tennessee   \n",
       "3    $50,000 - $74,999  White or Caucasian    New Jersey   \n",
       "4     $150,000 or more  White or Caucasian       Georgia   \n",
       "5     $150,000 or more  White or Caucasian    California   \n",
       "6    $25,000 - $49,999  White or Caucasian  Pennsylvania   \n",
       "7  $100,000 - $149,999               Other    California   \n",
       "8    Less than $25,000  White or Caucasian    California   \n",
       "9    $75,000 - $99,999  White or Caucasian          Ohio   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...        ABIS_BOOK   \n",
       "1  THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...        ABIS_BOOK   \n",
       "2                          Wellington: The Iron Duke        ABIS_BOOK   \n",
       "3                                  Duck in the Truck        ABIS_BOOK   \n",
       "4  Sharpe's Regiment: Richard Sharpe and the Inva...        ABIS_BOOK   \n",
       "5                                          Deep Time        ABIS_BOOK   \n",
       "6  Collins German Dictionary Complete and Unabrid...        ABIS_BOOK   \n",
       "7  My Virgin Kitchen: Delicious recipes you can m...        ABIS_BOOK   \n",
       "8  Born into the Children of God: My life in a re...        ABIS_BOOK   \n",
       "9                                 Well Gardened Mind        ABIS_BOOK   \n",
       "\n",
       "  state_code  state_name     region  \n",
       "0         FL     Unknown    Unknown  \n",
       "1         TX       Texas      South  \n",
       "2         TN     Unknown    Unknown  \n",
       "3         NJ  New Jersey  Northeast  \n",
       "4         GA     Unknown    Unknown  \n",
       "5         CA  California       West  \n",
       "6         PA     Unknown    Unknown  \n",
       "7         CA  California       West  \n",
       "8         NJ  New Jersey  Northeast  \n",
       "9         OH     Unknown    Unknown  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_full = spark.sql(query)\n",
    "df_fact_full.limit(10).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395a0e6f-3ae3-47b0-9a03-8dcac8eb691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_id: long (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- purchase_price_per_unit: double (nullable = true)\n",
      " |-- quantity: double (nullable = true)\n",
      " |-- total_price: double (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- weekday_name: string (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị schema sau khi làm sạch\n",
    "df_fact_full.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12130c39-b328-4de0-b73e-0f91c5952467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kích thước dữ liệu: (1675015, 24)\n"
     ]
    }
   ],
   "source": [
    "# Đếm số dòng\n",
    "num_rows =df_fact_full.count()\n",
    "# Đếm số cột\n",
    "num_cols = len(df_fact_full.columns)\n",
    "print(f\"\\nKích thước dữ liệu: ({num_rows}, {num_cols})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1ad486-82fa-48c1-9ac8-b39ea1a6b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# =====================================================\n",
    "# Tính toán toàn bộ feature trong MỘT lần groupBy duy nhất\n",
    "# =====================================================\n",
    "df_final = (\n",
    "    df_fact_full.groupBy(\"customer_id\")\n",
    "    .agg(\n",
    "        # Tổng chi tiêu\n",
    "        F.sum(\"total_price\").alias(\"total_spend\"),\n",
    "\n",
    "        # Trung bình chi tiêu trên mỗi đơn hàng\n",
    "        (F.sum(\"total_price\") / F.countDistinct(\"time_id\")).alias(\"avg_order_value\"),\n",
    "\n",
    "        # Độ lệch chuẩn chi tiêu trên đơn hàng\n",
    "        F.stddev(\"total_price\").alias(\"std_order_value\"),\n",
    "\n",
    "        # Trung bình số lượng sản phẩm mỗi đơn\n",
    "        (F.sum(\"quantity\") / F.countDistinct(\"time_id\")).alias(\"avg_items_per_order\"),\n",
    "\n",
    "        # Tổng số đơn hàng\n",
    "        F.countDistinct(\"time_id\").alias(\"total_orders\"),\n",
    "\n",
    "        # Năm đầu và năm cuối hoạt động\n",
    "        F.min(\"year\").alias(\"first_year\"),\n",
    "        F.max(\"year\").alias(\"last_year\")\n",
    "    )\n",
    "    # Thêm số năm hoạt động và chi tiêu trung bình mỗi năm\n",
    "    .withColumn(\"years_active\", (F.col(\"last_year\") - F.col(\"first_year\") + 1))\n",
    "    .withColumn(\"years_active\", F.when(F.col(\"years_active\") <= 0, 1).otherwise(F.col(\"years_active\")))\n",
    "    .withColumn(\"avg_spend_per_year\", F.col(\"total_spend\") / F.col(\"years_active\"))\n",
    "    .na.fill(0)  # đảm bảo không có null\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b7f8c9-0d5d-49bd-9b65-bc13f73e69ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+------------------+------------------+------------------+-------------------+------------+------------+\n",
      "|customer_id      |total_spend       |avg_spend_per_year|avg_order_value   |std_order_value   |avg_items_per_order|total_orders|years_active|\n",
      "+-----------------+------------------+------------------+------------------+------------------+-------------------+------------+------------+\n",
      "|R_1l6oxKA9uiM9GUo|5212.49           |1042.498          |66.82679487179487 |37.65645361471535 |2.3205128205128207 |78          |5           |\n",
      "|R_1jO4s7oht3pyKEc|13041.71          |2173.6183333333333|60.37828703703703 |25.637963404064184|2.8333333333333335 |216         |6           |\n",
      "|R_10TV1zyi4yCEEkl|30578.98999999998 |5096.49833333333  |74.4014355231143  |83.67537499523928 |2.67639902676399   |411         |6           |\n",
      "|R_2dyITPHbbfmCXJn|16020.08          |2670.0133333333333|92.06942528735632 |49.117791465504325|3.1666666666666665 |174         |6           |\n",
      "|R_1eWdieBjoYJXAYv|24767.929999999982|4953.585999999997 |67.67193989071033 |65.04549121003791 |2.8333333333333335 |366         |5           |\n",
      "|R_1gG5xibh48txT6f|12724.66          |2120.7766666666666|46.61047619047619 |47.384431934237185|2.2747252747252746 |273         |6           |\n",
      "|R_s4I8huB9BOcWI5H|6469.200000000001 |1078.2            |43.41744966442953 |35.85350387750293 |1.8120805369127517 |149         |6           |\n",
      "|R_yrLrYUf4oFzOnjb|11494.750000000004|1915.7916666666672|33.708944281524936|27.92731369109286 |1.6334310850439884 |341         |6           |\n",
      "|R_2cmFD4NTF42JLfH|15259.73          |2543.2883333333334|177.43872093023256|58.27022565543955 |5.558139534883721  |86          |6           |\n",
      "|R_1mxX9jjBSLwxiDU|2752.5499999999997|458.75833333333327|12.983726415094338|10.983328823402713|1.1556603773584906 |212         |6           |\n",
      "+-----------------+------------------+------------------+------------------+------------------+-------------------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_final.select(\n",
    "    \"customer_id\",\n",
    "    \"total_spend\", \"avg_spend_per_year\",\n",
    "    \"avg_order_value\", \"std_order_value\",\n",
    "    \"avg_items_per_order\", \"total_orders\",\n",
    "    \"years_active\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1c723d-e8b7-4a94-8714-b03c1308949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4030 dòng | Test: 930 dòng\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "#  Xác định features & target\n",
    "# =====================================================\n",
    "num_features = [\n",
    "    \"total_spend\",\n",
    "    \"years_active\",\n",
    "    \"avg_order_value\",\n",
    "    \"std_order_value\",\n",
    "    \"avg_items_per_order\",\n",
    "    \"total_orders\"\n",
    "]\n",
    "target = \"avg_spend_per_year\"\n",
    "\n",
    "df_clean = df_final.na.drop(subset=num_features + [target])\n",
    "# Chia train/test\n",
    "train_df, test_df = df_clean.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Train: {train_df.count()} dòng | Test: {test_df.count()} dòng\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=num_features,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaledFeatures\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b98b7f-4d29-4587-994e-df2350d0a78a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee0c0e6-42d3-4139-9499-a1d1be0fb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      " - numTrees: 200\n",
      " - maxDepth: 12\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Pipeline mô hình Random Forest\n",
    "# --------------------------\n",
    "rf = RandomForestRegressor(\n",
    "    labelCol=target,\n",
    "    featuresCol=\"scaledFeatures\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "# --------------------------\n",
    "# Tập siêu tham số cần thử\n",
    "# --------------------------\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [50, 200])\n",
    "    .addGrid(rf.maxDepth, [8, 10, 12])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# TrainValidationSplit\n",
    "# --------------------------\n",
    "evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=rf_pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Huấn luyện mô hình\n",
    "# --------------------------\n",
    "rf_tvs_model = tvs.fit(train_df)\n",
    "\n",
    "# --------------------------\n",
    "# In thông tin mô hình tốt nhất\n",
    "# --------------------------\n",
    "best_rf = rf_tvs_model.bestModel.stages[-1]\n",
    "print(\"Best Model:\")\n",
    "print(\" - numTrees:\", best_rf.getNumTrees)\n",
    "print(\" - maxDepth:\", best_rf.getMaxDepth())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b93536-8503-4d36-b14a-93014a054d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9914\n",
      "R2 Test : 0.9684\n",
      "----------\n",
      "MAE Train: 53.4572\n",
      "MAE Test : 88.3366\n",
      "----------\n",
      "RMSE Train: 152.5212\n",
      "RMSE Test : 294.7476\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Đánh giá mô hình\n",
    "# --------------------------\n",
    "train_pred = rf_tvs_model.bestModel.transform(train_df)\n",
    "test_pred  = rf_tvs_model.bestModel.transform(test_df)\n",
    "\n",
    "metrics = ['r2', 'mae', 'rmse']\n",
    "for metric in metrics:\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=metric)\n",
    "    print(f\"{metric.upper()} Train:\", round(evaluator.evaluate(train_pred), 4))\n",
    "    print(f\"{metric.upper()} Test :\", round(evaluator.evaluate(test_pred), 4))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b30af01f-9e1b-4965-a6e5-792e448882fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Random Forest model to MLflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"Customer_Spending_Prediction\")\n",
    "\n",
    "# Tính metrics train/test\n",
    "metrics_dict = {}\n",
    "for metric in metrics:  # metrics = ['r2', 'mae', 'rmse']\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=metric)\n",
    "    metrics_dict[f\"{metric}_train\"] = round(evaluator.evaluate(train_pred), 4)\n",
    "    metrics_dict[f\"{metric}_test\"]  = round(evaluator.evaluate(test_pred), 4)\n",
    "\n",
    "# Lưu vào MLflow\n",
    "with mlflow.start_run(run_name=\"RandomForest_Model\"):\n",
    "    # Log param\n",
    "    mlflow.log_param(\"model\", \"RandomForestRegressor\")\n",
    "    mlflow.log_param(\"numTrees\", best_rf.getNumTrees)\n",
    "    mlflow.log_param(\"maxDepth\", best_rf.getMaxDepth())\n",
    "    \n",
    "    # Log metric\n",
    "    for k, v in metrics_dict.items():\n",
    "        mlflow.log_metric(k, v)\n",
    "    \n",
    "    # Log mô hình (PipelineModel đầy đủ)\n",
    "    mlflow.spark.log_model(rf_tvs_model.bestModel, \"rf_model\")\n",
    "\n",
    "    print(\"Logged Random Forest model to MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f619350-04b8-4f5e-9984-755284749e26",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3026dc2b-9bb4-43ab-84c6-8485e90c37b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 03:09:02,314 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,314 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,314 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,314 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,330 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,330 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,330 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:02,330 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:09:42,129 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,129 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,129 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,129 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,136 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,239 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,239 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,239 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:09:42,239 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:22,693 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:22,693 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:22,693 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:22,693 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:33,462 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:33,462 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:33,462 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:33,462 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:44,260 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:44,260 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:44,260 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:44,260 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:49,938 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:49,938 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:49,938 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:49,938 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:53,791 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:53,791 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:53,791 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:53,791 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:10:58,919 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:58,919 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:58,919 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:10:58,919 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:03,758 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:03,758 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:03,758 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:03,758 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:10,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:10,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:10,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:10,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:10,980 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:10,980 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:10,980 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:10,980 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,320 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,934 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,934 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,934 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:11,934 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:18,606 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:18,606 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:18,606 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:18,606 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:20,512 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:20,512 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:20,512 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:20,512 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:25,835 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:25,835 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:25,835 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:25,835 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:28,875 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:28,875 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:28,875 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:28,875 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:31,124 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:31,124 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:31,124 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:31,124 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:32,009 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:32,009 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:32,009 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:32,009 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:34,506 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:34,506 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:34,506 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:34,506 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:37,354 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:37,354 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:37,354 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:37,354 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:39,753 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:39,753 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:39,753 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:39,753 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:11:40,874 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:40,874 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:40,874 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:40,874 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:41,617 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:41,617 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:41,617 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:41,617 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:45,209 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:45,209 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:45,209 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:45,209 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:47,400 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:47,400 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:47,400 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:11:47,400 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:13:38,321 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:13:38,321 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:13:38,321 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:13:38,321 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-12 03:16:06,741 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:16:06,741 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:16:06,741 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-12 03:16:06,741 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# --------------------------\n",
    "# XGBoost Spark phân tán\n",
    "# --------------------------\n",
    "xgb = SparkXGBRegressor(\n",
    "    features_col=\"scaledFeatures\",\n",
    "    label_col=target,\n",
    "    num_workers=1,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method=\"hist\",\n",
    "    objective=\"reg:squarederror\"\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Pipeline\n",
    "# --------------------------\n",
    "xgb_pipeline = Pipeline(stages=[assembler, scaler, xgb])\n",
    "\n",
    "# --------------------------\n",
    "# Grid Search / TrainValidationSplit\n",
    "# --------------------------\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(xgb.max_depth, [4, 6])\n",
    "    .addGrid(xgb.n_estimators, [50, 100])\n",
    "    .addGrid(xgb.learning_rate, [0.05, 0.1])\n",
    "    .addGrid(xgb.subsample, [0.7, 0.8])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=target,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=xgb_pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4,   # chạy song song 4 mô hình\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Huấn luyện mô hình\n",
    "# --------------------------\n",
    "xgb_tvs_model = tvs.fit(train_df)\n",
    "\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201062e3-6bb3-4c0c-984d-a4e7a5494772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters (from grid search):\n",
      " - max_depth: 4\n",
      " - n_estimators: 100\n",
      " - learning_rate: 0.1\n",
      " - subsample: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Lấy mô hình tốt nhất\n",
    "best_xgb = xgb_tvs_model.bestModel.stages[-1]\n",
    "tuned_params = [\"max_depth\", \"n_estimators\", \"learning_rate\", \"subsample\"]\n",
    "print(\"Best XGBoost Parameters (from grid search):\")\n",
    "for p in tuned_params:\n",
    "    value = best_xgb.getOrDefault(best_xgb.getParam(p))\n",
    "    print(f\" - {p}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26f6417-e198-4769-b323-897b451d1a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9987\n",
      "R2 Test : 0.9905\n",
      "----------\n",
      "MAE Train: 33.9499\n",
      "MAE Test : 49.7622\n",
      "----------\n",
      "RMSE Train: 58.4547\n",
      "RMSE Test : 161.3474\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình\n",
    "# --------------------------\n",
    "train_pred = xgb_tvs_model.transform(train_df)\n",
    "test_pred  = xgb_tvs_model.transform(test_df)\n",
    "\n",
    "metrics = ['r2', 'mae', 'rmse']\n",
    "for metric in metrics:\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=metric)\n",
    "    print(f\"{metric.upper()} Train:\", round(evaluator.evaluate(train_pred), 4))\n",
    "    print(f\"{metric.upper()} Test :\", round(evaluator.evaluate(test_pred), 4))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b98de7-20d6-465e-a105-e6c3629be7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"XGBoost_Regression\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.spark.log_model(best_xgb, \"xgb_model\")\n",
    "    mlflow.log_metric(\"r2_train\", 0.9987)\n",
    "    mlflow.log_metric(\"r2_test\", 0.9905)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b3c9f6-aac9-4e61-a5f7-d20e5f9974af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_train: 0.9987\n",
      "r2_test: 0.9905\n",
      "mae_train: 33.9499\n",
      "mae_test: 49.7622\n",
      "rmse_train: 58.4547\n",
      "rmse_test: 161.3474\n",
      "Logged XGBoost Spark model to MLflow\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"Customer_Spending_Prediction\")\n",
    "\n",
    "# Tính metrics train/test\n",
    "metrics_dict = {}\n",
    "for metric in metrics:  # metrics = ['r2', 'mae', 'rmse']\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=metric)\n",
    "    metrics_dict[f\"{metric}_train\"] = round(evaluator.evaluate(xgb_tvs_model.transform(train_df)), 4)\n",
    "    metrics_dict[f\"{metric}_test\"]  = round(evaluator.evaluate(xgb_tvs_model.transform(test_df)), 4)\n",
    "\n",
    "# Lưu vào MLflow\n",
    "with mlflow.start_run(run_name=\"XGBoost_Model\"):\n",
    "    # Log param\n",
    "    mlflow.log_param(\"model\", \"SparkXGBRegressor\")\n",
    "    mlflow.log_param(\"max_depth\", best_xgb.getOrDefault(best_xgb.getParam(\"max_depth\")))\n",
    "    mlflow.log_param(\"n_estimators\", best_xgb.getOrDefault(best_xgb.getParam(\"n_estimators\")))\n",
    "    mlflow.log_param(\"learning_rate\", best_xgb.getOrDefault(best_xgb.getParam(\"learning_rate\")))\n",
    "    mlflow.log_param(\"subsample\", best_xgb.getOrDefault(best_xgb.getParam(\"subsample\")))\n",
    "    \n",
    "    # Log metric\n",
    "    for k, v in metrics_dict.items():\n",
    "        mlflow.log_metric(k, v)\n",
    "        print(f\"{k}: {v}\")\n",
    "    \n",
    "    # Log mô hình (PipelineModel đầy đủ: assembler + scaler + XGB)\n",
    "    mlflow.spark.log_model(xgb_tvs_model.bestModel, \"xgb_model\")\n",
    "\n",
    "    print(\"Logged XGBoost Spark model to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fcfdc-48a5-4257-b47b-3fab58439167",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.spark.log_model(\n",
    "    best_xgb,\n",
    "    artifact_path=\"xgb_model\",\n",
    "    registered_model_name=\"XGB_Model\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3938809a-38df-41cf-95de-f0761e2ccbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "\n",
    "AWS_ACCESS_KEY = \"minioadmin\"\n",
    "AWS_SECRET_KEY = \"minioadmin\"\n",
    "AWS_S3_ENDPOINT = \"http://minio_server:9000\"\n",
    "WAREHOUSE = \"s3a://gold/\" \n",
    "NESSIE_URI = \"http://nessie:19120/api/v1\"\n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "    .setAppName(\"Lakehouse-Iceberg-TrainModel\")  \n",
    "    .set('spark.jars.packages',\n",
    "         'org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.1,'\n",
    "         'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.3_2.12:0.67.0,'\n",
    "         'org.apache.hadoop:hadoop-aws:3.3.4,'\n",
    "         'com.amazonaws:aws-java-sdk-bundle:1.12.300')\n",
    "    .set(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .set(\"spark.sql.catalog.nessie.uri\", NESSIE_URI)\n",
    "    .set(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .set(\"spark.sql.catalog.nessie.authentication.type\", \"NONE\")\n",
    "    .set(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .set(\"spark.sql.catalog.nessie.warehouse\", WAREHOUSE)\n",
    "    .set(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "    .set(\"spark.sql.catalog.nessie.s3.endpoint\", AWS_S3_ENDPOINT)\n",
    "    .set(\"spark.sql.catalog.nessie.s3.access-key\", AWS_ACCESS_KEY)\n",
    "    .set(\"spark.sql.catalog.nessie.s3.secret-key\", AWS_SECRET_KEY)\n",
    "    .set(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "    .set(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf) \n",
    "    .config(\"spark.driver.memory\", \"4g\") \n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105d4ecd-7d4a-446b-8b59-1b7ffc51941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact = spark.table(\"nessie.fact_order\")\n",
    "df_customer = spark.table(\"nessie.dim_customer\")\n",
    "df_product = spark.table(\"nessie.dim_product\")\n",
    "df_time = spark.table(\"nessie.dim_time\")\n",
    "df_location = spark.table(\"nessie.dim_location\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f97ced0-bfab-4433-97bd-5fa2b8955071",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT  \n",
    "    f.time_id,\n",
    "    f.customer_id,\n",
    "    f.product_id,\n",
    "    f.location_id,\n",
    "    f.purchase_price_per_unit,\n",
    "    f.quantity,\n",
    "    f.total_price,\n",
    "\n",
    "    -- Dim_time\n",
    "    t.order_date,\n",
    "    t.year,\n",
    "    t.month,\n",
    "    t.day,\n",
    "    t.quarter,\n",
    "    t.weekday_name,\n",
    "\n",
    "    -- Dim_customer\n",
    "    c.age_group,\n",
    "    c.gender,\n",
    "    c.education,\n",
    "    c.income,\n",
    "    c.race,\n",
    "    c.state,\n",
    "\n",
    "    -- Dim_product\n",
    "    p.product_title,\n",
    "    p.product_category,\n",
    "\n",
    "    -- Dim_location\n",
    "    l.state_code,\n",
    "    l.state_name,\n",
    "    l.region\n",
    "\n",
    "FROM nessie.fact_order AS f\n",
    "LEFT JOIN nessie.dim_time AS t ON f.time_id = t.time_id\n",
    "LEFT JOIN nessie.dim_customer AS c ON f.customer_id = c.customer_id\n",
    "LEFT JOIN nessie.dim_product AS p ON f.product_id = p.product_id\n",
    "LEFT JOIN nessie.dim_location AS l ON f.location_id = l.location_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3deb046f-023a-42fe-ae24-d91bc914fefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>purchase_price_per_unit</th>\n",
       "      <th>quantity</th>\n",
       "      <th>total_price</th>\n",
       "      <th>order_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "      <th>race</th>\n",
       "      <th>state</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439</td>\n",
       "      <td>R_1jZkLNE1JdtyVpH</td>\n",
       "      <td>000217653X</td>\n",
       "      <td>44</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.99</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>Less than $25,000</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Florida</td>\n",
       "      <td>THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>FL</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439</td>\n",
       "      <td>R_1jZkLNE1JdtyVpH</td>\n",
       "      <td>000217653X</td>\n",
       "      <td>39</td>\n",
       "      <td>13.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.55</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>Less than $25,000</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Florida</td>\n",
       "      <td>THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444</td>\n",
       "      <td>R_3qIPMah81MezsJn</td>\n",
       "      <td>0007137508</td>\n",
       "      <td>33</td>\n",
       "      <td>19.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.95</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>$50,000 - $74,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Wellington: The Iron Duke</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>TN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>428</td>\n",
       "      <td>R_vD2O13NgdnWBXMt</td>\n",
       "      <td>0007302622</td>\n",
       "      <td>4</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$50,000 - $74,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Duck in the Truck</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573</td>\n",
       "      <td>R_1QsZS0nI2sw5gl5</td>\n",
       "      <td>000745287X</td>\n",
       "      <td>41</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.96</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Sharpe's Regiment: Richard Sharpe and the Inva...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>GA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1815</td>\n",
       "      <td>R_2aldwxmUZox7Yfd</td>\n",
       "      <td>0007483791</td>\n",
       "      <td>16</td>\n",
       "      <td>10.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>California</td>\n",
       "      <td>Deep Time</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>R_3GD1CL4OyjglmbZ</td>\n",
       "      <td>0007510837</td>\n",
       "      <td>36</td>\n",
       "      <td>24.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.04</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Collins German Dictionary Complete and Unabrid...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>PA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>328</td>\n",
       "      <td>R_3Pc1ZZfNy58AvgE</td>\n",
       "      <td>0007544790</td>\n",
       "      <td>16</td>\n",
       "      <td>18.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>$100,000 - $149,999</td>\n",
       "      <td>Other</td>\n",
       "      <td>California</td>\n",
       "      <td>My Virgin Kitchen: Delicious recipes you can m...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>354</td>\n",
       "      <td>R_27Nf8ImFlWu3J9O</td>\n",
       "      <td>000756032X</td>\n",
       "      <td>4</td>\n",
       "      <td>9.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2018-06-20</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>Less than $25,000</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>California</td>\n",
       "      <td>Born into the Children of God: My life in a re...</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1201</td>\n",
       "      <td>R_3Pp1HTLxoglta9u</td>\n",
       "      <td>0008100713</td>\n",
       "      <td>32</td>\n",
       "      <td>23.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$75,000 - $99,999</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Well Gardened Mind</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>OH</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id        customer_id  product_id  location_id  \\\n",
       "0      439  R_1jZkLNE1JdtyVpH  000217653X           44   \n",
       "1      439  R_1jZkLNE1JdtyVpH  000217653X           39   \n",
       "2      444  R_3qIPMah81MezsJn  0007137508           33   \n",
       "3      428  R_vD2O13NgdnWBXMt  0007302622            4   \n",
       "4     1573  R_1QsZS0nI2sw5gl5  000745287X           41   \n",
       "5     1815  R_2aldwxmUZox7Yfd  0007483791           16   \n",
       "6       23  R_3GD1CL4OyjglmbZ  0007510837           36   \n",
       "7      328  R_3Pc1ZZfNy58AvgE  0007544790           16   \n",
       "8      354  R_27Nf8ImFlWu3J9O  000756032X            4   \n",
       "9     1201  R_3Pp1HTLxoglta9u  0008100713           32   \n",
       "\n",
       "   purchase_price_per_unit  quantity  total_price  order_date  year  month  \\\n",
       "0                    29.99       1.0        29.99  2020-09-16  2020      9   \n",
       "1                    13.55       1.0        13.55  2020-09-16  2020      9   \n",
       "2                    19.95       1.0        19.95  2022-12-05  2022     12   \n",
       "3                    13.25       1.0        13.25  2019-08-10  2019      8   \n",
       "4                    14.96       1.0        14.96  2022-06-27  2022      6   \n",
       "5                    10.84       1.0        10.84  2018-03-21  2018      3   \n",
       "6                    24.04       1.0        24.04  2020-01-21  2020      1   \n",
       "7                    18.72       1.0        18.72  2019-07-23  2019      7   \n",
       "8                     9.99       1.0         9.99  2018-06-20  2018      6   \n",
       "9                    23.08       1.0        23.08  2022-06-08  2022      6   \n",
       "\n",
       "   ...  gender                                          education  \\\n",
       "0  ...  Female                         High school diploma or GED   \n",
       "1  ...  Female                         High school diploma or GED   \n",
       "2  ...    Male                                  Bachelor's degree   \n",
       "3  ...  Female  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "4  ...    Male  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "5  ...    Male  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "6  ...  Female                         High school diploma or GED   \n",
       "7  ...    Male                                  Bachelor's degree   \n",
       "8  ...    Male                         High school diploma or GED   \n",
       "9  ...    Male  Graduate or professional degree (MA, MS, MBA, ...   \n",
       "\n",
       "                income                race         state  \\\n",
       "0    Less than $25,000  White or Caucasian       Florida   \n",
       "1    Less than $25,000  White or Caucasian       Florida   \n",
       "2    $50,000 - $74,999  White or Caucasian     Tennessee   \n",
       "3    $50,000 - $74,999  White or Caucasian    New Jersey   \n",
       "4     $150,000 or more  White or Caucasian       Georgia   \n",
       "5     $150,000 or more  White or Caucasian    California   \n",
       "6    $25,000 - $49,999  White or Caucasian  Pennsylvania   \n",
       "7  $100,000 - $149,999               Other    California   \n",
       "8    Less than $25,000  White or Caucasian    California   \n",
       "9    $75,000 - $99,999  White or Caucasian          Ohio   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...        ABIS_BOOK   \n",
       "1  THE DINAH'S CUPBOARD COOK BOOK: Recipes and Me...        ABIS_BOOK   \n",
       "2                          Wellington: The Iron Duke        ABIS_BOOK   \n",
       "3                                  Duck in the Truck        ABIS_BOOK   \n",
       "4  Sharpe's Regiment: Richard Sharpe and the Inva...        ABIS_BOOK   \n",
       "5                                          Deep Time        ABIS_BOOK   \n",
       "6  Collins German Dictionary Complete and Unabrid...        ABIS_BOOK   \n",
       "7  My Virgin Kitchen: Delicious recipes you can m...        ABIS_BOOK   \n",
       "8  Born into the Children of God: My life in a re...        ABIS_BOOK   \n",
       "9                                 Well Gardened Mind        ABIS_BOOK   \n",
       "\n",
       "  state_code  state_name     region  \n",
       "0         FL     Unknown    Unknown  \n",
       "1         TX       Texas      South  \n",
       "2         TN     Unknown    Unknown  \n",
       "3         NJ  New Jersey  Northeast  \n",
       "4         GA     Unknown    Unknown  \n",
       "5         CA  California       West  \n",
       "6         PA     Unknown    Unknown  \n",
       "7         CA  California       West  \n",
       "8         NJ  New Jersey  Northeast  \n",
       "9         OH     Unknown    Unknown  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_full = spark.sql(query)\n",
    "df_fact_full.limit(10).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a759118-12db-41b0-9692-7e1832c1540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_id: long (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- purchase_price_per_unit: double (nullable = true)\n",
      " |-- quantity: double (nullable = true)\n",
      " |-- total_price: double (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- weekday_name: string (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị schema sau khi làm sạch\n",
    "df_fact_full.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc8cbed-990b-41da-8085-2e305aae0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kích thước dữ liệu: (1675015, 24)\n"
     ]
    }
   ],
   "source": [
    "# Đếm số dòng\n",
    "num_rows =df_fact_full.count()\n",
    "# Đếm số cột\n",
    "num_cols = len(df_fact_full.columns)\n",
    "print(f\"\\nKích thước dữ liệu: ({num_rows}, {num_cols})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13764286-81ac-4f50-a72d-4dddd99d59d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4917 | Test: 4776\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "\n",
    "# =========================================\n",
    "# Tạo cột amount\n",
    "# =========================================\n",
    "df_fact_full = df_fact_full.withColumn(\"amount\", F.col(\"purchase_price_per_unit\") * F.col(\"quantity\"))\n",
    "\n",
    "# =========================================\n",
    "# Split train/test theo KH\n",
    "# =========================================\n",
    "all_customers = df_fact_full.select('customer_id').distinct()\n",
    "train_customers = all_customers.sample(False, 0.8, seed=42)\n",
    "test_customers = all_customers.subtract(train_customers)\n",
    "\n",
    "train_orders = df_fact_full.join(train_customers, on='customer_id', how='inner')\n",
    "test_orders  = df_fact_full.join(test_customers, on='customer_id', how='inner')\n",
    "\n",
    "# =========================================\n",
    "# Tạo feature numeric\n",
    "# =========================================\n",
    "def make_features(df):\n",
    "    df_numeric = df.groupBy(\"customer_id\").agg(\n",
    "        F.sum(\"amount\").alias(\"total_spend\"),\n",
    "        F.count(\"amount\").alias(\"n_orders\"),\n",
    "        F.avg(\"amount\").alias(\"avg_order_value\"),\n",
    "        F.stddev(\"amount\").alias(\"std_order_value\"),\n",
    "        (F.sum(\"quantity\") / F.countDistinct(\"time_id\")).alias(\"avg_items_per_order\"),\n",
    "        F.countDistinct(\"time_id\").alias(\"total_orders\"),\n",
    "        F.min(\"year\").alias(\"first_year\"),\n",
    "        F.max(\"year\").alias(\"last_year\")\n",
    "    ).withColumn(\n",
    "        \"years_active\", F.col(\"last_year\") - F.col(\"first_year\") + 1\n",
    "    ).withColumn(\n",
    "        \"years_active\", F.when(F.col(\"years_active\") <= 0, 1).otherwise(F.col(\"years_active\"))\n",
    "    ).fillna({'std_order_value': 0})\n",
    "    return df_numeric\n",
    "\n",
    "train_features = make_features(train_orders)\n",
    "test_features  = make_features(test_orders)\n",
    "\n",
    "# =========================================\n",
    "# Merge category mua nhiều nhất\n",
    "# =========================================\n",
    "def add_most_freq_category(df_orders, df_features):\n",
    "    df_cat = df_orders.groupBy(\"customer_id\", \"product_category\").agg(F.count(\"*\").alias(\"cnt\"))\n",
    "    w_cat = Window.partitionBy(\"customer_id\").orderBy(F.desc(\"cnt\"))\n",
    "    df_cat_rank = df_cat.withColumn(\"rank\", F.row_number().over(w_cat))\n",
    "    df_most_freq_category = df_cat_rank.filter(F.col(\"rank\")==1) \\\n",
    "        .select(\"customer_id\", F.col(\"product_category\").alias(\"most_freq_category\"))\n",
    "    return df_features.join(df_most_freq_category, on='customer_id', how='left')\n",
    "\n",
    "train_features = add_most_freq_category(train_orders, train_features)\n",
    "test_features  = add_most_freq_category(test_orders, test_features)\n",
    "\n",
    "# =========================================\n",
    "# Merge demographics\n",
    "# =========================================\n",
    "demographics_cols = ['gender','education','income','state']\n",
    "df_demo = df_fact_full.select('customer_id', *demographics_cols).dropDuplicates(['customer_id'])\n",
    "train_features = train_features.join(df_demo, on='customer_id', how='left')\n",
    "test_features  = test_features.join(df_demo, on='customer_id', how='left')\n",
    "\n",
    "# =========================================\n",
    "# Tạo target next_year_orders\n",
    "# =========================================\n",
    "def make_target(df_orders):\n",
    "    df_target = df_orders.groupBy('customer_id','year').agg(F.count(\"*\").alias(\"orders_per_year\"))\n",
    "    w = Window.partitionBy(\"customer_id\").orderBy(\"year\")\n",
    "    df_target = df_target.withColumn(\"next_year_orders\", F.lead(\"orders_per_year\",1).over(w))\n",
    "    df_target = df_target.select(\"customer_id\", \"next_year_orders\")\n",
    "    return df_target\n",
    "\n",
    "train_target = make_target(train_orders)\n",
    "test_target  = make_target(test_orders)\n",
    "\n",
    "train_df = train_features.join(train_target, on='customer_id', how='left').fillna({'next_year_orders':0})\n",
    "test_df  = test_features.join(test_target, on='customer_id', how='left').fillna({'next_year_orders':0})\n",
    "\n",
    "print(f\"Train: {train_df.count()} | Test: {test_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe5fab6b-ee44-4a60-a29c-b421c8c11f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train sample ===\n",
      "+-----------------+------------------+--------+------------------+------------------+-------------------+------------+----------+---------+------------+-------------------------+------+--------------------------------------------------------------------+-------------------+--------------+----------------+\n",
      "|customer_id      |total_spend       |n_orders|avg_order_value   |std_order_value   |avg_items_per_order|total_orders|first_year|last_year|years_active|most_freq_category       |gender|education                                                           |income             |state         |next_year_orders|\n",
      "+-----------------+------------------+--------+------------------+------------------+-------------------+------------+----------+---------+------------+-------------------------+------+--------------------------------------------------------------------+-------------------+--------------+----------------+\n",
      "|R_1l6oxKA9uiM9GUo|3730.0200000000004|132     |28.257727272727276|37.62160617628959 |2.2222222222222223 |63          |2018      |2021     |4           |ABIS_BOOK                |Male  |High school diploma or GED                                          |$150,000 or more   |North Carolina|75              |\n",
      "|R_10TV1zyi4yCEEkl|21391.01999999999 |796     |26.873140703517574|55.386510756423114|2.621794871794872  |312         |2018      |2021     |4           |NUTRITIONAL_SUPPLEMENT   |Male  |High school diploma or GED                                          |$50,000 - $74,999  |Texas         |276             |\n",
      "|R_2dyITPHbbfmCXJn|12292.970000000001|409     |30.056161369193156|51.52763521039809 |3.317829457364341  |129         |2018      |2021     |4           |SEXUAL_STIMULATION_DEVICE|Male  |Bachelor's degree                                                   |$150,000 or more   |Washington    |133             |\n",
      "|R_1eWdieBjoYJXAYv|19058.589999999993|644     |29.594083850931668|76.95211138691589 |2.6449275362318843 |276         |2018      |2021     |4           |ABIS_BOOK                |Female|High school diploma or GED                                          |$50,000 - $74,999  |Maryland      |286             |\n",
      "|R_1gG5xibh48txT6f|9341.120000000003 |415     |22.508722891566272|55.7516749997098  |2.2233502538071064 |197         |2018      |2021     |4           |NAIL_POLISH              |Female|Graduate or professional degree (MA, MS, MBA, PhD, JD, MD, DDS, etc)|$100,000 - $149,999|Wisconsin     |125             |\n",
      "|R_s4I8huB9BOcWI5H|5359.27           |222     |24.140855855855857|36.674203426956026|1.821705426356589  |129         |2018      |2021     |4           |NUTRITIONAL_SUPPLEMENT   |Female|Bachelor's degree                                                   |$75,000 - $99,999  |Michigan      |81              |\n",
      "|R_yrLrYUf4oFzOnjb|7934.460000000002 |386     |20.555595854922284|28.099690505896174|1.7435897435897436 |234         |2018      |2021     |4           |PET_FOOD                 |Male  |Bachelor's degree                                                   |$75,000 - $99,999  |Georgia       |143             |\n",
      "|R_21vtzOUrbyaVnsL|815.22            |56      |14.557500000000001|11.26094510001068 |2.4347826086956523 |23          |2018      |2020     |3           |SKIN_CLEANING_WIPE       |Female|High school diploma or GED                                          |Less than $25,000  |Colorado      |20              |\n",
      "|R_297dOANqCntVXou|9205.190000000002 |465     |19.796107526881727|27.57820443813405 |2.267605633802817  |213         |2018      |2021     |4           |PET_SUPPLIES             |Female|Bachelor's degree                                                   |$75,000 - $99,999  |Michigan      |218             |\n",
      "|R_1esG9Jlh9NISLaO|3641.9700000000003|172     |21.17424418604651 |43.07818706932536 |2.1097560975609757 |82          |2018      |2021     |4           |ABIS_BOOK                |Male  |High school diploma or GED                                          |$25,000 - $49,999  |Florida       |50              |\n",
      "+-----------------+------------------+--------+------------------+------------------+-------------------+------------+----------+---------+------------+-------------------------+------+--------------------------------------------------------------------+-------------------+--------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In 10 dòng đầu train\n",
    "print(\"=== Train sample ===\")\n",
    "train_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914208bb-2524-494d-b323-beea9ee83f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7️⃣ Chuẩn bị features\n",
    "# =========================================\n",
    "target = 'next_year_orders'\n",
    "numeric_features = ['total_spend','n_orders','avg_order_value','std_order_value',\n",
    "                    'avg_items_per_order','total_orders','years_active']\n",
    "categorical_features = ['most_freq_category','gender','education','income','state']\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid=\"keep\") for c in categorical_features]\n",
    "encoders = [OneHotEncoder(inputCol=c+\"_idx\", outputCol=c+\"_ohe\") for c in categorical_features]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=numeric_features + [c+\"_ohe\" for c in categorical_features],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaledFeatures\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc3d9cd-e277-47a3-b22c-b049e95ecc0f",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a4bb04-56c2-4c09-b326-e008f4d8ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Model:\n",
      " - numTrees: 100\n",
      " - maxDepth: 12\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# --------------------------\n",
    "# Pipeline mô hình Random Forest\n",
    "# --------------------------\n",
    "rf = RandomForestRegressor(\n",
    "    labelCol=target,\n",
    "    featuresCol=\"scaledFeatures\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, rf])\n",
    "\n",
    "# --------------------------\n",
    "# Tập siêu tham số cần thử\n",
    "# --------------------------\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [50, 100])\n",
    "    .addGrid(rf.maxDepth, [10, 12])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# TrainValidationSplit\n",
    "# --------------------------\n",
    "evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=rf_pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Huấn luyện mô hình\n",
    "# --------------------------\n",
    "rf_tvs_model = tvs.fit(train_df)\n",
    "\n",
    "# --------------------------\n",
    "# In thông tin mô hình tốt nhất\n",
    "# --------------------------\n",
    "best_rf = rf_tvs_model.bestModel.stages[-1]\n",
    "print(\"Best Random Forest Model:\")\n",
    "print(\" - numTrees:\", best_rf.getNumTrees)\n",
    "print(\" - maxDepth:\", best_rf.getMaxDepth())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98e1f502-51c6-4469-84e6-c89089bdbb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9695\n",
      "R2 Test : -inf\n",
      "----------\n",
      "MAE Train: 13.1937\n",
      "MAE Test : 34.3256\n",
      "----------\n",
      "RMSE Train: 21.3745\n",
      "RMSE Test : 65.8976\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Đánh giá mô hình\n",
    "# --------------------------\n",
    "train_pred = rf_tvs_model.bestModel.transform(train_df)\n",
    "test_pred  = rf_tvs_model.bestModel.transform(test_df)\n",
    "\n",
    "metrics = ['r2', 'mae', 'rmse']\n",
    "for metric in metrics:\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=metric)\n",
    "    print(f\"{metric.upper()} Train:\", round(evaluator.evaluate(train_pred), 4))\n",
    "    print(f\"{metric.upper()} Test :\", round(evaluator.evaluate(test_pred), 4))\n",
    "    print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eef4f4-deba-4994-9894-fd478a1230e0",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4aa224-7ddf-4b2d-b981-d5076ef6ed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 12:33:26,563 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,563 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,560 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,568 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,563 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,560 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,563 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,584 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,560 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,568 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,584 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,560 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,568 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,568 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,584 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:26,584 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:33:54,103 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,103 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,130 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,103 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,132 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,130 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,132 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,103 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,130 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,130 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,132 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,132 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,434 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,434 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,434 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:33:54,434 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:35:47,284 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:35:47,284 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:35:47,284 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:35:47,284 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,334 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,334 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,435 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,334 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,435 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,334 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,435 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,435 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,743 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,743 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,743 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:07,743 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:36:18,961 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:18,961 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:18,961 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:18,961 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:44,566 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:44,566 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:44,566 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:44,566 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:47,599 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:47,599 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:47,599 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:47,599 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:49,158 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:49,158 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:49,158 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:36:49,158 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:13,337 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:13,337 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:13,337 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:13,337 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:32,684 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:32,684 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:32,684 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:32,684 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:34,417 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:34,417 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:34,417 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:34,417 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:37,918 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:37,918 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:37,918 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:37,918 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:38,097 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:38,097 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:38,097 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:38,097 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:37:48,151 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:48,151 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:48,151 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:37:48,151 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:36,023 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:36,023 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:36,023 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:36,023 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:38,503 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:38,503 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:38,503 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:38,503 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:38:41,217 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:41,217 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:41,217 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:41,217 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:51,050 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:51,050 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:51,050 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:51,050 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:58,287 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:58,287 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:58,287 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:38:58,287 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:39:15,087 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:15,087 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:15,087 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:15,087 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:19,339 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:19,339 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:19,339 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:19,339 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:23,377 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:39:23,377 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:39:23,377 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:39:23,377 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:39:24,598 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:24,598 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:24,598 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:24,598 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:30,891 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:30,891 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:30,891 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:39:30,891 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:43:35,456 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:43:35,456 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:43:35,456 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:43:35,456 INFO XGBoost-PySpark: _fit Running xgboost-3.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.7, 'tree_method': 'hist', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-13 12:45:39,137 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:45:39,137 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:45:39,137 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-11-13 12:45:39,137 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# --------------------------\n",
    "# XGBoost Spark phân tán\n",
    "# --------------------------\n",
    "xgb = SparkXGBRegressor(\n",
    "    features_col=\"scaledFeatures\",\n",
    "    label_col=target,\n",
    "    num_workers=1,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method=\"hist\",\n",
    "    objective=\"reg:squarederror\"\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Pipeline\n",
    "# --------------------------\n",
    "xgb_pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, xgb])\n",
    "# --------------------------\n",
    "# Grid Search / TrainValidationSplit\n",
    "# --------------------------\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(xgb.max_depth, [4, 6])\n",
    "    .addGrid(xgb.n_estimators, [50, 100])\n",
    "    .addGrid(xgb.learning_rate, [0.05, 0.1])\n",
    "    .addGrid(xgb.subsample, [0.7, 0.8])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=target,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=xgb_pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Huấn luyện mô hình\n",
    "# --------------------------\n",
    "xgb_tvs_model = tvs.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eb890b2-91ad-4547-bc48-4e49e86f387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters (from grid search):\n",
      " - max_depth: 6\n",
      " - n_estimators: 100\n",
      " - learning_rate: 0.05\n",
      " - subsample: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Lấy mô hình tốt nhất\n",
    "best_xgb = xgb_tvs_model.bestModel.stages[-1]\n",
    "tuned_params = [\"max_depth\", \"n_estimators\", \"learning_rate\", \"subsample\"]\n",
    "print(\"Best XGBoost Parameters (from grid search):\")\n",
    "for p in tuned_params:\n",
    "    value = best_xgb.getOrDefault(best_xgb.getParam(p))\n",
    "    print(f\" - {p}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634a07fe-618a-4c56-a11e-f6a57f981ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.9623\n",
      "R2 Test : -inf\n",
      "----------\n",
      "MAE Train: 15.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m RegressionEvaluator(labelCol\u001b[38;5;241m=\u001b[39mtarget, predictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, metricName\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(evaluator\u001b[38;5;241m.\u001b[39mevaluate(train_pred), \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Test :\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pred\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Dự đoán & đánh giá\n",
    "# --------------------------\n",
    "train_pred = xgb_tvs_model.bestModel.transform(train_df)\n",
    "test_pred  = xgb_tvs_model.bestModel.transform(test_df)\n",
    "\n",
    "metrics = ['r2', 'mae', 'rmse']\n",
    "for metric in metrics:\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=metric)\n",
    "    print(f\"{metric.upper()} Train:\", round(evaluator.evaluate(train_pred), 4))\n",
    "    print(f\"{metric.upper()} Test :\", round(evaluator.evaluate(test_pred), 4))\n",
    "    print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60699f0a-da28-453e-899e-83f476cffda0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

from config_spark import get_spark_session

def process_fields_file(filename="fields.csv"):
    """
    Äá»c file fields tá»« MinIO (bronze) â†’ xá»­ lÃ½ â†’ ghi vÃ o Iceberg (silver)
    Náº¿u báº£ng chÆ°a tá»“n táº¡i, táº¡o má»›i; náº¿u Ä‘Ã£ cÃ³, append dá»¯ liá»‡u.
    """
    spark = get_spark_session("Fields-Bronze-to-Silver")

    bronze_path = f"s3a://bronze/ecommerse/{filename}"
    print(f"ğŸ“¥ Äang Ä‘á»c file: {bronze_path}")

    # 1ï¸âƒ£ Äá»c file CSV tá»« MinIO (Bronze)
    df_fields = spark.read \
        .option("header", "true") \
        .option("inferSchema", "true") \
        .csv(bronze_path)

    print(f"ğŸ“Š Sá»‘ dÃ²ng ban Ä‘áº§u: {df_fields.count()}")

    # 2ï¸âƒ£ LÃ m sáº¡ch dá»¯ liá»‡u
    df_fields_clean = df_fields.na.drop()
    print(f"ğŸ§¹ Sau khi loáº¡i bá» null: {df_fields_clean.count()} dÃ²ng cÃ²n láº¡i")

    # 3ï¸âƒ£ Ghi vÃ o báº£ng Iceberg (Silver)
    table_name = "nessie.fields"
    existing_tables = [t.name for t in spark.catalog.listTables("nessie")]

    if table_name.split(".")[-1] in existing_tables:
        print(f"ğŸ’¾ Báº£ng {table_name} Ä‘Ã£ tá»“n táº¡i â†’ append dá»¯ liá»‡u")
        df_fields_clean.writeTo(table_name).append()
    else:
        print(f"ğŸ’¾ Báº£ng {table_name} chÆ°a tá»“n táº¡i â†’ táº¡o báº£ng má»›i")
        df_fields_clean.writeTo(table_name).create()

    print(f"âœ… HoÃ n táº¥t xá»­ lÃ½ file: {filename}")
    spark.stop()
